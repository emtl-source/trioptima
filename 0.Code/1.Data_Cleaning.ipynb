{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRS_2023_ValueTrain.csv\n",
      "Removed Columns:\n",
      "\n",
      "Remaining Columns:\n",
      "['action', 'assetClass', 'cleared', 'customBasketIndicator', 'deliveryType', 'effectiveDate', 'event', 'eventDateTime', 'executionDateTime', 'expirationDate', 'instrumentType', 'leg1FixedRateDayCount', 'leg1FloatingRateDayCount', 'leg1NotionalAmount', 'leg1NotionalCurrency', 'leg1NotionalScheduleType', 'leg1SettlementCurrency', 'leg1UnderlyingAssetOrContractType', 'leg2FloatingRateDayCount', 'leg2NotionalAmount', 'leg2NotionalCurrency', 'leg2NotionalScheduleType', 'leg2ResetFrequencyMultiplier', 'leg2SettlementCurrency', 'nonStandardTermIndicator', 'packageIndicator', 'platformID', 'postPricedSwapIndicator', 'primeBrokerageTransactionIndicator', 'productName', 'leg1FixedRate', 'leg1FixedRatePaymentFrequencyMultiplier', 'leg1FixedRatePaymentFrequencyPeriod', 'leg2FloatingRatePaymentFrequencyMultiplier', 'leg2FloatingRatePaymentFrequencyPeriod', 'leg2UnderlierCurrency', 'leg2UnderlierID', 'leg2UnderlierIDSource', 'leg2UnderlierTenorMultiplier', 'leg2UnderlierTenorPeriod', 'leg2ResetFrequencyPeriod', 'CurrencyIV', 'NominalIV']\n",
      "\n",
      "Number of Remaining Columns in Train Data: 43\n",
      "\n",
      "Remaining Columns in Test Data: Index(['action', 'assetClass', 'cleared', 'customBasketIndicator',\n",
      "       'deliveryType', 'effectiveDate', 'event', 'eventDateTime',\n",
      "       'executionDateTime', 'expirationDate', 'instrumentType',\n",
      "       'leg1FixedRateDayCount', 'leg1FloatingRateDayCount',\n",
      "       'leg1NotionalAmount', 'leg1NotionalCurrency',\n",
      "       'leg1NotionalScheduleType', 'leg1SettlementCurrency',\n",
      "       'leg1UnderlyingAssetOrContractType', 'leg2FloatingRateDayCount',\n",
      "       'leg2NotionalAmount', 'leg2NotionalCurrency',\n",
      "       'leg2NotionalScheduleType', 'leg2ResetFrequencyMultiplier',\n",
      "       'leg2SettlementCurrency', 'nonStandardTermIndicator',\n",
      "       'packageIndicator', 'platformID', 'postPricedSwapIndicator',\n",
      "       'primeBrokerageTransactionIndicator', 'productName', 'leg1FixedRate',\n",
      "       'leg1FixedRatePaymentFrequencyMultiplier',\n",
      "       'leg1FixedRatePaymentFrequencyPeriod',\n",
      "       'leg2FloatingRatePaymentFrequencyMultiplier',\n",
      "       'leg2FloatingRatePaymentFrequencyPeriod', 'leg2UnderlierCurrency',\n",
      "       'leg2UnderlierID', 'leg2UnderlierIDSource',\n",
      "       'leg2UnderlierTenorMultiplier', 'leg2UnderlierTenorPeriod',\n",
      "       'leg2ResetFrequencyPeriod', 'CurrencyIV', 'NominalIV'],\n",
      "      dtype='object')\n",
      "\n",
      "Number of Data Points in Train Data: 4972\n",
      "\n",
      "Removed Columns:\n",
      "['amendmentIndicator', 'blockTradeIndicator', 'embeddedOptionType', 'firstExerciseDate', 'leg1CallAmount', 'leg1CallCurrency', 'leg1EffectiveNotionalAmount', 'leg1NotionalEffectiveDate', 'leg1NotionalEndDate', 'leg1PutAmount', 'leg1PutCurrency', 'leg1ResetFrequencyMultiplier', 'leg1SettlementLocation', 'leg2CallAmount', 'leg2CallCurrency', 'leg2EffectiveNotionalAmount', 'leg2FixedRateDayCount', 'leg2NotionalEffectiveDate', 'leg2NotionalEndDate', 'leg2PutAmount', 'leg2PutCurrency', 'leg2SettlementLocation', 'leg2UnderlyingAssetOrContractType', 'optionExerciseFrequencyMultiplier', 'optionExerciseFrequencyPeriod', 'optionPremiumAmount', 'optionPremiumCurrency', 'optionStrikePrice', 'optionStrikePriceCurrency', 'optionStrikePriceNotation', 'optionStyle', 'optionType', 'originalDisseminationIdentifier', 'otherPaymentAmount', 'otherPaymentCurrency', 'otherPaymentType', 'packageTransactionPrice', 'packageTransactionPriceCurrency', 'packageTransactionPriceNotation', 'packageTransactionSpread', 'packageTransactionSpreadCurrency', 'packageTransactionSpreadNotation', 'productCode', 'productCodeType', 'returnTriggerType', 'underlierExpirationDate', 'futureValueNotional', 'leg1FloatingRatePaymentFrequencyMultiplier', 'leg1FloatingRatePaymentFrequencyPeriod', 'leg1Spread', 'leg1SpreadCurrency', 'leg1SpreadNotation', 'leg1UnderlierCurrency', 'leg1UnderlierID', 'leg1UnderlierIDSource', 'leg1UnderlierTenorMultiplier', 'leg1UnderlierTenorPeriod', 'leg2FixedRatePaymentFrequencyMultiplier', 'leg2FixedRatePaymentFrequencyPeriod', 'leg2Spread', 'leg2SpreadCurrency', 'leg2SpreadNotation', 'multiCurrencyIndicator', 'leg1ResetFrequencyPeriod', 'optionExerciseEndDate', 'leg2FixedRate']\n",
      "IRS_2023_CurrencyTest.csv\n",
      "\n",
      "Number of Remaining Columns in Test Data: 46\n",
      "\n",
      "Number of Data Points in Test Data: 26\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load your data\n",
    "#r'C:/Users/gusta/Documents/KTH/TriOptima/trioptima/trioptima/'\n",
    "#'/Users/elliotlindestam/Documents/Skola/Indek icloud/trioptima/'\n",
    "your_path = r'C:/Users/gusta/Documents/KTH/TriOptima/trioptima/trioptima/'\n",
    "test_folder_path = your_path + '6.Active Data/Test Data/'\n",
    "train_folder_path = your_path + '6.Active Data/Train Model Data/'\n",
    "\n",
    "def clean_train(folder_path):\n",
    "    try:\n",
    "        # Get file in the folder\n",
    "        files = os.listdir(folder_path)\n",
    "        #MAC Issue\n",
    "        files = [f for f in files if f != '.DS_Store']\n",
    "        file = files[0]\n",
    "        file_name = files[0][:-4]\n",
    "        \n",
    "        # Check if there are any files\n",
    "        if len(files) == 0:\n",
    "            print(\"No files found in the folder.\")\n",
    "\n",
    "        else:\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            data = pd.read_csv(file_path, dtype=str)\n",
    "            print(file)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    # Drop 'disseminationTimestamp' and its derived columns\n",
    "    data = data.drop(columns=['disseminationTimestamp','sDRreceiptTimestamp','disseminationIdentifier'])\n",
    "\n",
    "    # Convert any empty strings to NaN\n",
    "    data = data.map(lambda x: None if x == '' else x)\n",
    "\n",
    "    # Set your threshold\n",
    "    threshold = 0.3 * len(data)\n",
    "\n",
    "    # Collect removed columns and percentages\n",
    "    removed_columns = []\n",
    "    nan_percentages = []\n",
    "\n",
    "    # Identify columns to be removed and collect their names and NaN percentages\n",
    "    for column in data.columns:\n",
    "        nan_count = data[column].isna().sum()\n",
    "        nan_percentage = nan_count / len(data)\n",
    "        \n",
    "        if nan_percentage >= 0.3:\n",
    "            removed_columns.append(column)\n",
    "            nan_percentages.append(f\"{nan_percentage:.2%}\")\n",
    "\n",
    "    # Display removed columns and percentages in a table\n",
    "    removed_data = pd.DataFrame({\n",
    "        'Removed Column': removed_columns,\n",
    "        '% NaN Values': nan_percentages\n",
    "    })\n",
    "    print(\"Removed Columns:\")\n",
    "    \n",
    "    # Create Interaction variables\n",
    "    data['CurrencyIV'] = data.apply(lambda row: compare_item(row, 'leg1NotionalCurrency','leg2NotionalCurrency'), axis=1)\n",
    "    data['NominalIV'] = data.apply(lambda row: compare_item(row, 'leg1NotionalAmount','leg2NotionalAmount'), axis=1)\n",
    "    \n",
    "\n",
    "    # Remove identified columns\n",
    "    data = data.drop(columns=removed_columns)\n",
    "\n",
    "    # Display remaining columns\n",
    "    remaining_columns = list(data.columns)\n",
    "    print(\"\\nRemaining Columns:\")\n",
    "    print(remaining_columns)\n",
    "\n",
    "    # Display the number of remaining columns\n",
    "    print(f\"\\nNumber of Remaining Columns in Train Data: {len(remaining_columns)}\")\n",
    "    print(f\"\\nRemaining Columns in Test Data: {data.columns}\")\n",
    "    print(f\"\\nNumber of Data Points in Train Data: {len(data)}\")\n",
    "    print(\"\\nRemoved Columns:\")\n",
    "    print(removed_columns)\n",
    "\n",
    "    # Write cleaned data back to CSV\n",
    "    # Replace 'cleaned_file.csv' with the desired name/path for your output file\n",
    "    cleaned_file_path = your_path + \"2.Cleaned/\" + file_name + '_Cleaned.csv'\n",
    "    data.to_csv(cleaned_file_path, index=False)\n",
    "    return removed_columns\n",
    "\n",
    "def compare_item(row,leg1,leg2):\n",
    "    return 1 if row[leg1] == row[leg2] else 0\n",
    "\n",
    "def clean_test(fp, r_col):\n",
    "    \n",
    "    try:\n",
    "        # Get file in the folder\n",
    "        files = os.listdir(fp)\n",
    "        files = [f for f in files if f != '.DS_Store']\n",
    "        file = files[0]\n",
    "        file_name = files[0][:-4]\n",
    "        \n",
    "        # Check if there are any files\n",
    "        if len(files) == 0:\n",
    "            print(\"No files found in the folder.\")\n",
    "\n",
    "        else:\n",
    "            file_path = os.path.join(fp, file)\n",
    "            data = pd.read_csv(file_path, dtype=str)\n",
    "            print(file)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    #data = data.drop(columns=r_col+['disseminationTimestamp','sDRreceiptTimestamp','disseminationIdentifier'])\n",
    "    \n",
    "    data = data.drop(columns=r_col)\n",
    "\n",
    "    # Convert any empty strings to NaN\n",
    "    data = data.map(lambda x: None if x == '' else x)\n",
    "\n",
    "    # Create interaction variable\n",
    "    data['CurrencyIV'] = data.apply(lambda row: compare_item(row, 'leg1NotionalCurrency','leg2NotionalCurrency'), axis=1)\n",
    "    data['NominalIV'] = data.apply(lambda row: compare_item(row, 'leg1NotionalAmount','leg2NotionalAmount'), axis=1)\n",
    "\n",
    "    print(f\"\\nNumber of Remaining Columns in Test Data: {len(data.columns)}\")\n",
    "    #print(data.columns)\n",
    "    print(f\"\\nNumber of Data Points in Test Data: {len(data)}\")\n",
    "    cleaned_file_path = your_path + \"2.Cleaned/\" + file_name + '_Cleaned.csv'\n",
    "    data.to_csv(cleaned_file_path, index=False)\n",
    "    \n",
    "    \n",
    "\n",
    "removed_cols = clean_train(train_folder_path)\n",
    "clean_test(test_folder_path,removed_cols)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
